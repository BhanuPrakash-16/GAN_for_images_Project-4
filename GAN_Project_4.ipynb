{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM560Qb+HK+O45HKKtjKVSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhanuPrakash-16/GAN_for_images_Project-4/blob/main/GAN_Project_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZNGwzsva57n",
        "outputId": "9cdd52f8-a1df-4068-d4c8-d9102326f4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.12/dist-packages (4.3.1)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.3)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Module-1 Global Parameter setting and Importing\n",
        "\n",
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import subprocess\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "\n",
        "!pip install wfdb # Install wfdb package\n",
        "import wfdb\n",
        "\n",
        "\n",
        "import csv\n",
        "import logging\n",
        "from datetime import datetime   # âœ… REQUIRED\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "\n",
        "\n",
        "SEQ_LEN = 1248\n",
        "LATENT_DIM = 100\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 2\n",
        "N_CRITIC = 5\n",
        "LR = 1e-4\n",
        "GP_LAMBDA = 10.0\n",
        "\n",
        "# =========================================================\n",
        "# CONFIG\n",
        "# =========================================================\n",
        "FS = 300        # Sampling rate for PhysioNet 2017\n",
        "LOWCUT = 0.5\n",
        "HIGHCUT = 40.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 2 Data set loading and preprocessing\n",
        "\n",
        "# =========================================================\n",
        "# PREPROCESSING\n",
        "# =========================================================\n",
        "\n",
        "def bandpass_filter(signal, fs, low=0.5, high=40.0):\n",
        "    \"\"\"\n",
        "    Band-pass filter for ECG (baseline wander + noise removal)\n",
        "    \"\"\"\n",
        "    b, a = butter(\n",
        "        N=4,\n",
        "        Wn=[low / (fs / 2), high / (fs / 2)],\n",
        "        btype=\"band\"\n",
        "    )\n",
        "    return filtfilt(b, a, signal)\n",
        "\n",
        "\n",
        "def normalize(signal):\n",
        "    \"\"\"\n",
        "    Z-score normalization\n",
        "    \"\"\"\n",
        "    return (signal - np.mean(signal)) / (np.std(signal) + 1e-8)\n",
        "\n",
        "\n",
        "def preprocess_ecg_segment(segment, fs, target_len):\n",
        "    \"\"\"\n",
        "    Preprocess ECG segment and ENFORCE fixed length\n",
        "    (CRITICAL for GAN stability)\n",
        "    \"\"\"\n",
        "    segment = bandpass_filter(segment, fs)\n",
        "    segment = normalize(segment)\n",
        "\n",
        "    # enforce exact length\n",
        "    if len(segment) > target_len:\n",
        "        segment = segment[:target_len]\n",
        "    elif len(segment) < target_len:\n",
        "        pad_len = target_len - len(segment)\n",
        "        segment = np.pad(segment, (0, pad_len), mode=\"constant\")\n",
        "\n",
        "    return segment.astype(\"float32\")\n",
        "\n",
        "# =========================================================\n",
        "# SEGMENTATION\n",
        "# =========================================================\n",
        "\n",
        "def segment_ecg(signal, seq_len):\n",
        "    \"\"\"\n",
        "    Split long ECG signal into non-overlapping fixed windows\n",
        "    \"\"\"\n",
        "    return [\n",
        "        signal[i:i + seq_len]\n",
        "        for i in range(0, len(signal) - seq_len + 1, seq_len)\n",
        "    ]\n",
        "\n",
        "# =========================================================\n",
        "# PHYSIONET DIRECTORY LOADER\n",
        "# =========================================================\n",
        "\n",
        "def load_physionet_ecg(\n",
        "    physionet_dir,\n",
        "    seq_len=1250,\n",
        "    lead_index=0\n",
        "):\n",
        "    \"\"\"\n",
        "    Load, preprocess, and segment PhysioNet ECG data\n",
        "    from a local directory containing .hea/.dat files\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.isdir(physionet_dir):\n",
        "        raise FileNotFoundError(\n",
        "            f\"PhysioNet directory not found: {physionet_dir}\"\n",
        "        )\n",
        "\n",
        "    all_segments = []\n",
        "\n",
        "    print(f\"[INFO] Scanning PhysioNet directory: {physionet_dir}\")\n",
        "\n",
        "    for file in os.listdir(physionet_dir):\n",
        "        if file.endswith(\".hea\"):\n",
        "            record_name = file.replace(\".hea\", \"\")\n",
        "            record_path = os.path.join(physionet_dir, record_name)\n",
        "\n",
        "            # Load ECG record\n",
        "            record = wfdb.rdrecord(record_path)\n",
        "            fs = record.fs\n",
        "            signal = record.p_signal[:, lead_index]\n",
        "\n",
        "            # Segment signal\n",
        "            segments = segment_ecg(signal, seq_len)\n",
        "\n",
        "            for seg in segments:\n",
        "                seg = preprocess_ecg_segment(\n",
        "                    seg,\n",
        "                    fs=fs,\n",
        "                    target_len=seq_len\n",
        "                )\n",
        "                all_segments.append(seg)\n",
        "\n",
        "    if not all_segments:\n",
        "        raise RuntimeError(\n",
        "            \"No ECG segments extracted. \"\n",
        "            \"Check PhysioNet directory contents.\"\n",
        "        )\n",
        "\n",
        "    ecg_array = np.array(all_segments)[..., np.newaxis]\n",
        "\n",
        "    print(f\"[INFO] Total ECG segments loaded : {ecg_array.shape[0]}\")\n",
        "    print(f\"[INFO] Segment shape              : {ecg_array.shape[1:]}\")\n",
        "\n",
        "    # ğŸ” Safety check\n",
        "    assert ecg_array.shape[1] == seq_len, (\n",
        "        f\"Segment length mismatch: expected {seq_len}, \"\n",
        "        f\"got {ecg_array.shape[1]}\"\n",
        "    )\n",
        "\n",
        "    return ecg_array\n",
        "\n",
        "# =========================================================\n",
        "# TENSORFLOW DATASET CONVERSION\n",
        "# =========================================================\n",
        "\n",
        "def get_tf_dataset(ecg_array, batch_size, shuffle=True):\n",
        "    \"\"\"\n",
        "    Convert NumPy ECG array to tf.data.Dataset\n",
        "    \"\"\"\n",
        "    ds = tf.data.Dataset.from_tensor_slices(ecg_array)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=1024)\n",
        "\n",
        "    ds = ds.batch(batch_size, drop_remainder=True)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "KUENtGMMa_P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 3 Build Generator\n",
        "\n",
        "def build_generator(seq_len, latent_dim):\n",
        "    \"\"\"\n",
        "    Builds and returns the ECG Generator model\n",
        "    (NO printing here)\n",
        "    \"\"\"\n",
        "\n",
        "    z = layers.Input(shape=(latent_dim,), name=\"latent_vector\")\n",
        "\n",
        "    x = layers.Dense((seq_len // 8) * 128, name=\"dense_projection\")(z)\n",
        "    x = layers.Reshape((seq_len // 8, 128), name=\"reshape\")(x)\n",
        "\n",
        "    for i, filters in enumerate([128, 64, 32], start=1):\n",
        "        x = layers.UpSampling1D(2, name=f\"upsample_{i}\")(x)\n",
        "        x = layers.Conv1D(filters, 5, padding=\"same\", name=f\"conv1d_{i}\")(x)\n",
        "        x = layers.BatchNormalization(name=f\"bn_{i}\")(x)\n",
        "        x = layers.ReLU(name=f\"relu_{i}\")(x)\n",
        "\n",
        "    out = layers.Conv1D(\n",
        "        1, 7, padding=\"same\", activation=\"tanh\", name=\"ecg_output\"\n",
        "    )(x)\n",
        "\n",
        "    model = Model(z, out, name=\"ECG_Generator\")\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "generator = build_generator(SEQ_LEN, LATENT_DIM)\n",
        "\n",
        "# PRINT ARCHITECTURE OUTSIDE THE FUNCTION\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ECG GENERATOR ARCHITECTURE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "generator.summary()\n",
        "\n",
        "print(\"=\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "ZwnVqCekbBPY",
        "outputId": "c4d6c22e-eef3-4375-aa90-09d8db3da4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ECG GENERATOR ARCHITECTURE\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ECG_Generator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_Generator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ latent_vector (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_projection (\u001b[38;5;33mDense\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19968\u001b[0m)          â”‚     \u001b[38;5;34m2,016,768\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ upsample_1 (\u001b[38;5;33mUpSampling1D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m82,048\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1 (\u001b[38;5;33mBatchNormalization\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ relu_1 (\u001b[38;5;33mReLU\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ upsample_2 (\u001b[38;5;33mUpSampling1D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m41,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2 (\u001b[38;5;33mBatchNormalization\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ relu_2 (\u001b[38;5;33mReLU\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ upsample_3 (\u001b[38;5;33mUpSampling1D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m64\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m32\u001b[0m)       â”‚        \u001b[38;5;34m10,272\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_3 (\u001b[38;5;33mBatchNormalization\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m32\u001b[0m)       â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ relu_3 (\u001b[38;5;33mReLU\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m32\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ ecg_output (\u001b[38;5;33mConv1D\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m1\u001b[0m)        â”‚           \u001b[38;5;34m225\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ latent_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_projection (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19968</span>)          â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,016,768</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ upsample_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ relu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ upsample_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ relu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ upsample_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ relu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ ecg_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,151,233\u001b[0m (8.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,151,233</span> (8.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,150,785\u001b[0m (8.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,150,785</span> (8.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Module 4 Build Critic\n",
        "\n",
        "def build_critic(seq_len):\n",
        "    \"\"\"\n",
        "    Builds and returns the ECG Critic (WGAN-GP)\n",
        "    \"\"\"\n",
        "\n",
        "    ecg_input = layers.Input(\n",
        "        shape=(seq_len, 1),\n",
        "        name=\"ecg_input\"\n",
        "    )\n",
        "\n",
        "    x = ecg_input\n",
        "\n",
        "    for i, filters in enumerate([32, 64, 128, 256], start=1):\n",
        "        x = layers.Conv1D(\n",
        "            filters=filters,\n",
        "            kernel_size=5,\n",
        "            strides=2,\n",
        "            padding=\"same\",\n",
        "            name=f\"conv1d_{i}\"\n",
        "        )(x)\n",
        "        # âœ… FIX: use negative_slope instead of alpha\n",
        "        x = layers.LeakyReLU(\n",
        "            negative_slope=0.2,\n",
        "            name=f\"leaky_relu_{i}\"\n",
        "        )(x)\n",
        "\n",
        "    x = layers.Flatten(name=\"flatten\")(x)\n",
        "\n",
        "    critic_output = layers.Dense(\n",
        "        1,\n",
        "        name=\"critic_score\"\n",
        "    )(x)y\n",
        "\n",
        "    model = Model(\n",
        "        inputs=ecg_input,\n",
        "        outputs=critic_output,\n",
        "        name=\"ECG_Critic\"\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ------------------ USAGE ------------------\n",
        "\n",
        "critic = build_critic(SEQ_LEN)\n",
        "\n",
        "# PRINT ARCHITECTURE OUTSIDE THE FUNCTION\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ECG Critic ARCHITECTURE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "critic.summary()\n",
        "\n",
        "print(\"=\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "En2aty4ebG2d",
        "outputId": "f7c5007f-2d1f-48fa-c667-93333310d19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ECG Critic ARCHITECTURE\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ECG_Critic\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_Critic\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ ecg_input (\u001b[38;5;33mInputLayer\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1248\u001b[0m, \u001b[38;5;34m1\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m192\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m624\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m41,088\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m156\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m256\u001b[0m)        â”‚       \u001b[38;5;34m164,096\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m256\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19968\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ critic_score (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚        \u001b[38;5;34m19,969\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ ecg_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_relu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19968</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ critic_score (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,969</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,649\u001b[0m (920.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,649</span> (920.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,649\u001b[0m (920.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,649</span> (920.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monitoring and controlling code\n",
        "\n",
        "class WGANMonitor:\n",
        "    \"\"\"\n",
        "    Monitoring and control module for WGAN training\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        log_dir=\"logs\",\n",
        "        patience=10,\n",
        "        min_delta=0.001\n",
        "    ):\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "        self.writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "\n",
        "        self.best_g_loss = np.inf\n",
        "        self.wait = 0\n",
        "\n",
        "        self.g_history = []\n",
        "        self.c_history = []\n",
        "\n",
        "        print(f\"[Monitor] Logging to: {log_dir}\")\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # LOG LOSSES\n",
        "    # -----------------------------------------------------\n",
        "    def log(self, epoch, g_loss, c_loss):\n",
        "\n",
        "        g_loss = float(g_loss)\n",
        "        c_loss = float(c_loss)\n",
        "\n",
        "        self.g_history.append(g_loss)\n",
        "        self.c_history.append(c_loss)\n",
        "\n",
        "        with self.writer.as_default():\n",
        "            tf.summary.scalar(\"Generator_Loss\", g_loss, step=epoch)\n",
        "            tf.summary.scalar(\"Critic_Loss\", c_loss, step=epoch)\n",
        "\n",
        "        print(\n",
        "            f\"[Monitor] Epoch {epoch} | \"\n",
        "            f\"G Loss: {g_loss:.4f} | \"\n",
        "            f\"C Loss: {c_loss:.4f}\"\n",
        "        )\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # CHECK FOR NaN\n",
        "    # -----------------------------------------------------\n",
        "    def check_nan(self, g_loss, c_loss):\n",
        "        if np.isnan(g_loss) or np.isnan(c_loss):\n",
        "            print(\"[Monitor] NaN detected! Stopping training.\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # EARLY STOPPING\n",
        "    # -----------------------------------------------------\n",
        "    def early_stopping(self, g_loss):\n",
        "        if g_loss < self.best_g_loss - self.min_delta:\n",
        "            self.best_g_loss = g_loss\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "\n",
        "        if self.wait >= self.patience:\n",
        "            print(\"[Monitor] Early stopping triggered.\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # PLOT FINAL LOSS CURVES\n",
        "    # -----------------------------------------------------\n",
        "    def plot_losses(self, save_path=None):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(self.g_history, label=\"Generator Loss\")\n",
        "        plt.plot(self.c_history, label=\"Critic Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"WGAN-GP Training Loss Curves\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # CLOSE WRITER\n",
        "    # -----------------------------------------------------\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "        print(\"[Monitor] TensorBoard writer closed.\")\n"
      ],
      "metadata": {
        "id": "fljqKdHGbJFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Revised Training Code with Monitoring & Control Included\n",
        "# =========================================================\n",
        "\n",
        "PHYSIONET_DIR = r\"C:\\Users\\drsas\\Project4\\Rawdata\\Physionet\"\n",
        "LEAD_INDEX = 0\n",
        "\n",
        "CHECKPOINT_DIR = r\"C:\\Users\\drsas\\Project4\\CheckPoints\"\n",
        "LOG_DIR = r\"C:\\Users\\drsas\\Project4\\Logs\"\n",
        "TB_LOG_DIR = os.path.join(LOG_DIR, \"tensorboard\")\n",
        "FINAL_MODEL_PATH = os.path.join(\n",
        "    CHECKPOINT_DIR,\n",
        "    \"ECG_Generator_PhysioNet_Final.h5\"\n",
        ")\n",
        "\n",
        "VIS_DIR = r\"C:\\Users\\drsas\\Project4\\final_visualizations\"\n",
        "\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "os.makedirs(TB_LOG_DIR, exist_ok=True)\n",
        "os.makedirs(VIS_DIR, exist_ok=True)\n",
        "\n",
        "# =========================================================\n",
        "# LOGGING SETUP\n",
        "# =========================================================\n",
        "log_file = os.path.join(\n",
        "    LOG_DIR,\n",
        "    f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
        ")\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename=log_file,\n",
        "    filemode=\"w\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
        ")\n",
        "\n",
        "logging.info(\"WGAN-GP Training Started\")\n",
        "\n",
        "# CSV logging\n",
        "csv_log_path = os.path.join(LOG_DIR, \"training_metrics.csv\")\n",
        "csv_file = open(csv_log_path, mode=\"w\", newline=\"\")\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow([\n",
        "    \"epoch\",\n",
        "    \"critic_loss\",\n",
        "    \"generator_loss\",\n",
        "    \"epoch_time_sec\",\n",
        "    \"checkpoint_saved\"\n",
        "])\n",
        "\n",
        "tb_writer = tf.summary.create_file_writer(TB_LOG_DIR)\n",
        "\n",
        "# =========================================================\n",
        "# MODULE 7: MONITOR INITIALIZATION\n",
        "# =========================================================\n",
        "monitor = WGANMonitor(\n",
        "    log_dir=TB_LOG_DIR,\n",
        "    patience=10\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# LOAD ECG DATA (MODULE 2)\n",
        "# =========================================================\n",
        "print(\"\\n[INFO] Loading PhysioNet ECG data...\")\n",
        "logging.info(\"Loading PhysioNet ECG data\")\n",
        "\n",
        "ecg_array = load_physionet_ecg(\n",
        "    physionet_dir=PHYSIONET_DIR,\n",
        "    seq_len=SEQ_LEN,\n",
        "    lead_index=LEAD_INDEX\n",
        ")\n",
        "\n",
        "dataset = get_tf_dataset(ecg_array, BATCH_SIZE)\n",
        "\n",
        "print(\"[INFO] ECG data ready\")\n",
        "logging.info(\"ECG data loaded successfully\")\n",
        "\n",
        "# =========================================================\n",
        "# BUILD MODELS\n",
        "# =========================================================\n",
        "print(\"\\n[INFO] Building Generator and Critic...\")\n",
        "generator = build_generator(SEQ_LEN, LATENT_DIM)\n",
        "critic = build_critic(SEQ_LEN)\n",
        "\n",
        "# =========================================================\n",
        "# OPTIMIZERS\n",
        "# =========================================================\n",
        "g_optimizer = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.9)\n",
        "c_optimizer = tf.keras.optimizers.Adam(LR, beta_1=0.5, beta_2=0.9)\n",
        "\n",
        "# =========================================================\n",
        "# CHECKPOINTING\n",
        "# =========================================================\n",
        "ckpt = tf.train.Checkpoint(\n",
        "    generator=generator,\n",
        "    critic=critic,\n",
        "    g_optimizer=g_optimizer,\n",
        "    c_optimizer=c_optimizer\n",
        ")\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(\n",
        "    ckpt,\n",
        "    CHECKPOINT_DIR,\n",
        "    max_to_keep=5\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# GRADIENT PENALTY\n",
        "# =========================================================\n",
        "def gradient_penalty(real, fake):\n",
        "    alpha = tf.random.uniform([real.shape[0], 1, 1], 0.0, 1.0)\n",
        "    interpolated = alpha * real + (1.0 - alpha) * fake\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated)\n",
        "        pred = critic(interpolated, training=True)\n",
        "\n",
        "    grads = tape.gradient(pred, interpolated)\n",
        "    grad_norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))\n",
        "\n",
        "    return tf.reduce_mean((grad_norm - 1.0) ** 2)\n",
        "\n",
        "# =========================================================\n",
        "# TRAINING STEPS\n",
        "# =========================================================\n",
        "@tf.function\n",
        "def train_critic(real_ecg):\n",
        "    z = tf.random.normal((BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        fake_ecg = generator(z, training=True)\n",
        "        c_real = critic(real_ecg, training=True)\n",
        "        c_fake = critic(fake_ecg, training=True)\n",
        "        gp = gradient_penalty(real_ecg, fake_ecg)\n",
        "\n",
        "        loss = (\n",
        "            tf.reduce_mean(c_fake)\n",
        "            - tf.reduce_mean(c_real)\n",
        "            + GP_LAMBDA * gp\n",
        "        )\n",
        "\n",
        "    grads = tape.gradient(loss, critic.trainable_variables)\n",
        "    c_optimizer.apply_gradients(zip(grads, critic.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_generator():\n",
        "    z = tf.random.normal((BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        fake_ecg = generator(z, training=True)\n",
        "        loss = -tf.reduce_mean(critic(fake_ecg, training=True))\n",
        "\n",
        "    grads = tape.gradient(loss, generator.trainable_variables)\n",
        "    g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "# =========================================================\n",
        "# TRAINING LOOP (WITH MONITORING & CONTROL)\n",
        "# =========================================================\n",
        "\n",
        "print(\"\\n[INFO] Starting WGAN-GP training...\\n\")\n",
        "\n",
        "epoch_c_loss_history = []\n",
        "epoch_g_loss_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    g_losses = []\n",
        "    c_losses = []\n",
        "\n",
        "    for real_batch in dataset:\n",
        "        for _ in range(N_CRITIC):\n",
        "            c_losses.append(train_critic(real_batch))\n",
        "\n",
        "        g_losses.append(train_generator())\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    mean_c_loss = float(tf.reduce_mean(c_losses))\n",
        "    mean_g_loss = float(tf.reduce_mean(g_losses))\n",
        "\n",
        "    epoch_c_loss_history.append(mean_c_loss)\n",
        "    epoch_g_loss_history.append(mean_g_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1:03d}/{EPOCHS}] | \"\n",
        "        f\"C Loss: {mean_c_loss:.4f} | \"\n",
        "        f\"G Loss: {mean_g_loss:.4f} | \"\n",
        "        f\"Time: {epoch_time:.2f}s\"\n",
        "    )\n",
        "\n",
        "    # ---------------- MONITOR ----------------\n",
        "    monitor.log(epoch + 1, mean_g_loss, mean_c_loss)\n",
        "\n",
        "    # NaN Detection\n",
        "    if monitor.check_nan(mean_g_loss, mean_c_loss):\n",
        "        print(\"[INFO] Training stopped due to NaN.\")\n",
        "        break\n",
        "\n",
        "    # Early Stopping\n",
        "    if monitor.early_stopping(mean_g_loss):\n",
        "        print(\"[INFO] Early stopping activated.\")\n",
        "        break\n",
        "\n",
        "    # ---------------- EXISTING CHECKPOINT ----------------\n",
        "    checkpoint_saved = \"NO\"\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_manager.save()\n",
        "        checkpoint_saved = \"YES\"\n",
        "\n",
        "    csv_writer.writerow([\n",
        "        epoch + 1,\n",
        "        mean_c_loss,\n",
        "        mean_g_loss,\n",
        "        epoch_time,\n",
        "        checkpoint_saved\n",
        "    ])\n",
        "\n",
        "    with tb_writer.as_default():\n",
        "        tf.summary.scalar(\"Critic_Loss\", mean_c_loss, step=epoch + 1)\n",
        "        tf.summary.scalar(\"Generator_Loss\", mean_g_loss, step=epoch + 1)\n",
        "\n",
        "print(\"\\n[INFO] Training completed\")\n",
        "monitor.close()\n",
        "\n",
        "# =========================================================\n",
        "# FINAL VISUALISATION (UNCHANGED)\n",
        "# =========================================================\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epoch_c_loss_history, label=\"Critic Loss\")\n",
        "plt.plot(epoch_g_loss_history, label=\"Generator Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"WGAN-GP Training Loss Curves\")\n",
        "plt.show()\n",
        "\n",
        "real_sample = ecg_array[0]\n",
        "z = tf.random.normal((1, LATENT_DIM))\n",
        "fake_sample = generator(z, training=False)[0].numpy()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(real_sample.squeeze(), label=\"Real ECG\")\n",
        "plt.plot(fake_sample.squeeze(), label=\"Generated ECG\")\n",
        "plt.legend()\n",
        "plt.title(\"Final Real vs Generated ECG\")\n",
        "plt.show()\n",
        "\n",
        "generator.save(FINAL_MODEL_PATH)\n",
        "print(f\"[INFO] Final Generator saved to: {FINAL_MODEL_PATH}\")\n",
        "\n",
        "csv_file.close()\n",
        "logging.info(\"Training completed and logs closed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "FwtvkMUcbLNo",
        "outputId": "6cf31966-4af7-4ed5-af10-651c3a70f78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Monitor] Logging to: C:\\Users\\drsas\\Project4\\Logs/tensorboard\n",
            "\n",
            "[INFO] Loading PhysioNet ECG data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "PhysioNet directory not found: C:\\Users\\drsas\\Project4\\Rawdata\\Physionet",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3913734462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading PhysioNet ECG data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m ecg_array = load_physionet_ecg(\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mphysionet_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPHYSIONET_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3885267831.py\u001b[0m in \u001b[0;36mload_physionet_ecg\u001b[0;34m(physionet_dir, seq_len, lead_index)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysionet_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         raise FileNotFoundError(\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;34mf\"PhysioNet directory not found: {physionet_dir}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: PhysioNet directory not found: C:\\Users\\drsas\\Project4\\Rawdata\\Physionet"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Module 8: Inference API + Inference Engine\n",
        "# =========================================================\n",
        "# =========================================================\n",
        "# ECG Inference Class\n",
        "# =========================================================\n",
        "class ECGInference:\n",
        "\n",
        "    def __init__(self, model_path, latent_dim=100):\n",
        "        \"\"\"\n",
        "        Initialize inference engine\n",
        "        \"\"\"\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Model not found at: {model_path}\")\n",
        "\n",
        "        print(f\"[Inference] Loading model from: {model_path}\")\n",
        "        self.generator = tf.keras.models.load_model(model_path)\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        print(\"[Inference] Model loaded successfully\")\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Generate ECG Samples\n",
        "    # -----------------------------------------------------\n",
        "    def generate(self, n_samples=1):\n",
        "        z = tf.random.normal((n_samples, self.latent_dim))\n",
        "        generated = self.generator(z, training=False).numpy()\n",
        "\n",
        "        print(f\"[Inference] Generated ECG shape: {generated.shape}\")\n",
        "        return generated\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Visualize ECG Signal\n",
        "    # -----------------------------------------------------\n",
        "    def visualize(self, ecg_array, index=0):\n",
        "        if index >= len(ecg_array):\n",
        "            raise ValueError(\"Index exceeds number of samples\")\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(ecg_array[index].squeeze())\n",
        "        plt.title(\"Generated ECG Signal\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Amplitude\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Save ECG Signals\n",
        "    # -----------------------------------------------------\n",
        "    def save(self, ecg_array, save_dir=\"generated_ecg\", format=\"npy\"):\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        if format == \"npy\":\n",
        "            path = os.path.join(save_dir, \"generated_ecg.npy\")\n",
        "            np.save(path, ecg_array)\n",
        "\n",
        "        elif format == \"csv\":\n",
        "            for i, sample in enumerate(ecg_array):\n",
        "                path = os.path.join(save_dir, f\"ecg_{i}.csv\")\n",
        "                np.savetxt(path, sample.squeeze(), delimiter=\",\")\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Format must be 'npy' or 'csv'\")\n",
        "\n",
        "        print(f\"[Inference] ECG saved to: {save_dir}\")\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Full Pipeline\n",
        "    # -----------------------------------------------------\n",
        "    def run(self, n_samples=1, save=False, save_dir=\"generated_ecg\"):\n",
        "        ecg = self.generate(n_samples)\n",
        "        self.visualize(ecg, index=0)\n",
        "\n",
        "        if save:\n",
        "            self.save(ecg, save_dir=save_dir)\n",
        "\n",
        "        return ecg\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# INFERENCE ENGINE IMPLEMENTATION\n",
        "# =========================================================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # ---------------- CONFIGURATION ----------------\n",
        "    MODEL_PATH = r\"C:\\Users\\drsas\\Project4\\CheckPoints\\ECG_Generator_PhysioNet_Final.h5\"\n",
        "    LATENT_DIM = 100\n",
        "    N_SAMPLES = 5\n",
        "    SAVE_OUTPUT = True\n",
        "    SAVE_DIR = r\"C:\\Users\\drsas\\Project4\\GeneratedECG\"\n",
        "\n",
        "    print(\"\\n[INFO] Starting Inference Engine...\\n\")\n",
        "\n",
        "    # ---------------- INITIALIZE ENGINE ----------------\n",
        "    engine = ECGInference(\n",
        "        model_path=MODEL_PATH,\n",
        "        latent_dim=LATENT_DIM\n",
        "    )\n",
        "\n",
        "    # ---------------- RUN INFERENCE ----------------\n",
        "    generated_ecg = engine.run(\n",
        "        n_samples=N_SAMPLES,\n",
        "        save=SAVE_OUTPUT,\n",
        "        save_dir=SAVE_DIR\n",
        "    )\n",
        "\n",
        "    print(\"\\n[INFO] Inference Completed Successfully\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_EnJLCeXbOQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# WGAN-Based Synthetic ECG Generator Deployment\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION\n",
        "# =========================================================\n",
        "MODEL_PATH = r\"C:\\Users\\drsas\\Project4\\CheckPoints\\ECG_Generator_PhysioNet_Final.h5\"\n",
        "LATENT_DIM = 100\n",
        "SEQ_LEN = 1248\n",
        "\n",
        "# =========================================================\n",
        "# PAGE SETTINGS\n",
        "# =========================================================\n",
        "st.set_page_config(\n",
        "    page_title=\"Synthetic ECG Generator\",\n",
        "    page_icon=\"ğŸ«€\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.title(\"ğŸ«€ WGAN-Based Synthetic ECG Generator\")\n",
        "st.write(\"Generate realistic synthetic ECG signals using trained WGAN-GP model.\")\n",
        "\n",
        "# =========================================================\n",
        "# LOAD MODEL SAFELY\n",
        "# =========================================================\n",
        "@st.cache_resource\n",
        "def load_generator(model_path):\n",
        "    if not os.path.exists(model_path):\n",
        "        return None\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "generator = load_generator(MODEL_PATH)\n",
        "\n",
        "if generator is None:\n",
        "    st.error(f\"âŒ Model file not found at:\\n{MODEL_PATH}\")\n",
        "    st.stop()\n",
        "\n",
        "st.success(\"âœ… Generator model loaded successfully\")\n",
        "\n",
        "# =========================================================\n",
        "# SIDEBAR CONTROLS\n",
        "# =========================================================\n",
        "st.sidebar.header(\"Generation Settings\")\n",
        "\n",
        "n_samples = st.sidebar.slider(\n",
        "    \"Number of ECG Samples\",\n",
        "    min_value=1,\n",
        "    max_value=20,\n",
        "    value=1\n",
        ")\n",
        "\n",
        "generate_button = st.sidebar.button(\"Generate ECG\")\n",
        "\n",
        "# =========================================================\n",
        "# GENERATION LOGIC\n",
        "# =========================================================\n",
        "if generate_button:\n",
        "\n",
        "    st.info(\"Generating ECG...\")\n",
        "\n",
        "    z = tf.random.normal((n_samples, LATENT_DIM))\n",
        "    generated_ecg = generator(z, training=False).numpy()\n",
        "\n",
        "    st.success(\"Generation complete!\")\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # DISPLAY ECG SIGNALS\n",
        "    # -----------------------------------------------------\n",
        "    for i in range(n_samples):\n",
        "\n",
        "        st.subheader(f\"Generated ECG Sample {i+1}\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 3))\n",
        "        ax.plot(generated_ecg[i].squeeze())\n",
        "        ax.set_title(\"Synthetic ECG Signal\")\n",
        "        ax.set_xlabel(\"Time\")\n",
        "        ax.set_ylabel(\"Amplitude\")\n",
        "        ax.grid(True)\n",
        "\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # DOWNLOAD OPTION\n",
        "    # -----------------------------------------------------\n",
        "    st.download_button(\n",
        "        label=\"Download Generated ECG (.npy)\",\n",
        "        data=np.array(generated_ecg).tobytes(),\n",
        "        file_name=\"generated_ecg.npy\",\n",
        "        mime=\"application/octet-stream\"\n",
        "    )\n",
        "\n",
        "# =========================================================\n",
        "# FOOTER\n",
        "# =========================================================\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Developed using WGAN-GP for Synthetic ECG Generation\")\n"
      ],
      "metadata": {
        "id": "lit8lJYZbQ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# ECG Classifier Using Real + GAN Generated Data\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURATION (MUST MATCH GAN TRAINING)\n",
        "# =========================================================\n",
        "SEQ_LEN = 1248\n",
        "LATENT_DIM = 100\n",
        "N_CLASSES = 2      # 0 = Real, 1 = Generated\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "PHYSIONET_DIR = r\"C:\\Users\\drsas\\Project4\\Rawdata\\Physionet\"\n",
        "GENERATED_DATA_PATH = r\"C:\\Users\\drsas\\Project4\\GeneratedECG\\generated_ecg.npy\"\n",
        "\n",
        "CHECKPOINT_DIR = r\"C:\\Users\\drsas\\Project4\\CheckPoints\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# =========================================================\n",
        "# BUILD CLASSIFIER\n",
        "# =========================================================\n",
        "def build_ecg_classifier(seq_len, n_classes):\n",
        "\n",
        "    ecg_input = layers.Input(shape=(seq_len, 1), name=\"ecg_input\")\n",
        "\n",
        "    x = ecg_input\n",
        "\n",
        "    for filters in [32, 64, 128]:\n",
        "        x = layers.Conv1D(filters, 5, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.MaxPooling1D(2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    output = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return Model(ecg_input, output, name=\"ECG_Classifier\")\n",
        "\n",
        "# =========================================================\n",
        "# LOAD REAL ECG DATA (Module 2)\n",
        "# =========================================================\n",
        "print(\"\\n[INFO] Loading real ECG from PhysioNet...\")\n",
        "\n",
        "X_real = load_physionet_ecg(\n",
        "    physionet_dir=PHYSIONET_DIR,\n",
        "    seq_len=SEQ_LEN,\n",
        "    lead_index=0\n",
        ")\n",
        "\n",
        "print(f\"[INFO] Real ECG shape: {X_real.shape}\")\n",
        "\n",
        "# =========================================================\n",
        "# LOAD GENERATED ECG DATA (Module 8 Output)\n",
        "# =========================================================\n",
        "print(\"[INFO] Loading generated ECG data...\")\n",
        "\n",
        "if not os.path.exists(GENERATED_DATA_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Generated ECG file not found at: {GENERATED_DATA_PATH}\"\n",
        "    )\n",
        "\n",
        "X_fake = np.load(GENERATED_DATA_PATH)\n",
        "\n",
        "if len(X_fake.shape) == 2:\n",
        "    X_fake = X_fake[..., np.newaxis]\n",
        "\n",
        "print(f\"[INFO] Generated ECG shape: {X_fake.shape}\")\n",
        "\n",
        "# =========================================================\n",
        "# CREATE LABELS\n",
        "# =========================================================\n",
        "y_real = np.zeros(len(X_real))     # Label 0\n",
        "y_fake = np.ones(len(X_fake))      # Label 1\n",
        "\n",
        "# Combine\n",
        "X = np.concatenate([X_real, X_fake], axis=0)\n",
        "y = np.concatenate([y_real, y_fake], axis=0)\n",
        "\n",
        "print(f\"[INFO] Combined dataset shape: {X.shape}\")\n",
        "\n",
        "# =========================================================\n",
        "# SPLIT DATA\n",
        "# =========================================================\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    stratify=y_temp,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"[INFO] Training samples: {len(X_train)}\")\n",
        "print(f\"[INFO] Validation samples: {len(X_val)}\")\n",
        "print(f\"[INFO] Test samples: {len(X_test)}\")\n",
        "\n",
        "# =========================================================\n",
        "# BUILD & COMPILE MODEL\n",
        "# =========================================================\n",
        "classifier = build_ecg_classifier(SEQ_LEN, N_CLASSES)\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "# =========================================================\n",
        "# TRAIN\n",
        "# =========================================================\n",
        "history = classifier.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# SAVE MODEL\n",
        "# =========================================================\n",
        "MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"ECG_Classifier_GAN.h5\")\n",
        "classifier.save(MODEL_PATH)\n",
        "\n",
        "print(f\"[INFO] Classifier saved at: {MODEL_PATH}\")\n",
        "\n",
        "# =========================================================\n",
        "# EVALUATION\n",
        "# =========================================================\n",
        "print(\"\\n[INFO] Evaluating classifier...\\n\")\n",
        "\n",
        "y_pred_prob = classifier.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix\\n\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "MuMlXhqabVgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}